Step 2 with dabl is to help find the best classifier

# Example using Titanic dataset

dabl will show you the best classifier to use

```python   
fc = dabl.SimpleClassifier(random_state=0)
X = titanic_clean.drop(“survived”, axis=1)
y = titanic_clean.survived

fc.fit(X, y) 
``` 

# Example using the Ames housing data

```python   
import dabl
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_digits

X, y = load_digits(return_X_y=True)

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)

sc = dabl.SimpleClassifier().fit(X_train, y_train)

print(“Accuracy score”, sc.score(X_test, y_test))
```
>>> Accuracy: 0.98

The super power of dabl is the one liner: 
```python   
dabl.plot(X, y)
```
![?](https://amueller.github.io/dabl/dev/_images/sphx_glr_plot_ames_003.png)
Automatically plots the categorical sin a bar plot

![?](https://amueller.github.io/dabl/dev/_images/sphx_glr_plot_splice_002.png
Also does a mosaic plot
